{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matt Viteri & Yu Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "This problem walks us through a problem discussed in detail in the Multi-level regression bookwritten  by  A.  Gelman  and  J.  Hill.   NYC  has  a  program  known  as  stop-and-frisk.   Relying  on  a60’s era ruling, the law allows an officer to search someone without arrest, and without probablecause,  if  the  officer  believes  s/he  might  be  in  danger  because  of  a  hidden  weapon.   Much  hasbeen  written  about  this,  as  it  has  come  under  significant  scrutiny  for  being  discriminative  andallowing (even encouraging) racial profiling.  You can read a summary of it at this Wikipedia page:https://en.wikipedia.org/wiki/Stop-and-frisk_in_New_York_City.The data you will download contain information about the number of traffic stops, reported perprecinct (75 total precincts), along with the ethnicity as reported by the police officer.  These datahave kept only three ethnicities:  white, black and hispanic.  The data set also has data on arrestrates in the previous year, broken down by four types of crimes; and the total population levels perprecinct per ethnic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\. Download and load the data in the file NYC_stop_and_frisk.dat, uploaded to Canvas.\n",
    "\n",
    "**Skiprows (below) will ignore the header information in the \"stop_and_frisk\" file. That information is repeated here:**\n",
    "\n",
    "stop and frisk data (with noise added to protect confidentiality)\n",
    "\n",
    "* precincts are numbered 1-75\n",
    "* ethnicity 1=black, 2=hispanic, 3=white\n",
    "* crime type 1=violent, 2=weapons, 3=property, 4=drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stops</th>\n",
       "      <th>pop</th>\n",
       "      <th>past_arrests</th>\n",
       "      <th>precint</th>\n",
       "      <th>eth</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>1720</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1720</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>1720</td>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1720</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1368</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stops   pop  past_arrests  precint  eth  crime\n",
       "0     75  1720           191        1    1      1\n",
       "1     36  1720            57        1    1      2\n",
       "2     74  1720           599        1    1      3\n",
       "3     17  1720           133        1    1      4\n",
       "4     37  1368            62        1    2      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NYC_stop_and_frisk.dat', skiprows=6, sep=' ')\n",
    "df.columns = ['stops', 'pop', 'past_arrests', 'precint', 'eth', 'crime']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\. What fraction of the total stops correspond to “white/back/hispanic”? What fraction of thepopulation corresponds to “white/black/hispanic”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop percentages:\n",
      "\n",
      "53.13 percent of the stops correspond to black\n",
      "33.95 percent of the stops correspond to hispanic\n",
      "12.92 percent of the stops correspond to white\n"
     ]
    }
   ],
   "source": [
    "print('Stop percentages:\\n')\n",
    "\n",
    "eth = {\n",
    "    1: 'black',\n",
    "    2: 'hispanic',\n",
    "    3: 'white'\n",
    "}\n",
    "\n",
    "totalStops = df.stops.sum()\n",
    "\n",
    "for k, v in eth.items():\n",
    "    perc = round((df[df.eth == k].stops.sum() / totalStops) * 100, 2)\n",
    "    print('{} percent of the stops correspond to {}'.format(perc, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population percentages:\n",
      "\n",
      "27.55 percent of the population correspond to black\n",
      "25.57 percent of the population correspond to hispanic\n",
      "46.88 percent of the population correspond to white\n"
     ]
    }
   ],
   "source": [
    "print('Population percentages:\\n')\n",
    "\n",
    "totalPop = df['pop'].sum()\n",
    "\n",
    "for k, v in eth.items():\n",
    "    perc = round((df[df.eth == k]['pop'].sum() / totalPop) * 100, 2)\n",
    "    print('{} percent of the population correspond to {}'.format(perc, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\. Use a Poisson regression to model the number of stops, controlling for ethnicity and using the number of past arrests as an exposure input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stops</th>\n",
       "      <th>pop</th>\n",
       "      <th>past_arrests</th>\n",
       "      <th>precint</th>\n",
       "      <th>crime</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>1720</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1720</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>1720</td>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1720</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1368</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stops   pop  past_arrests  precint  crime  black  hispanic  white\n",
       "0     75  1720           191        1      1      1         0      0\n",
       "1     36  1720            57        1      2      1         0      0\n",
       "2     74  1720           599        1      3      1         0      0\n",
       "3     17  1720           133        1      4      1         0      0\n",
       "4     37  1368            62        1      1      0         1      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map eth column to actual ethnicities\n",
    "df = pd.get_dummies(df, columns=['eth'])\n",
    "df = df.rename(columns={\"eth_1\": \"black\", \"eth_2\": \"hispanic\", \"eth_3\": \"white\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  stops   No. Observations:                  900\n",
      "Model:                            GLM   Df Residuals:                      896\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -94260.\n",
      "Date:                Thu, 17 Oct 2019   Deviance:                   1.8318e+05\n",
      "Time:                        10:28:11   Pearson chi2:                 2.79e+05\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.8002      0.009    -89.279      0.000      -0.818      -0.783\n",
      "pop         8.991e-07    8.1e-08     11.102      0.000     7.4e-07    1.06e-06\n",
      "black          0.1729      0.009     20.055      0.000       0.156       0.190\n",
      "hispanic       0.2463      0.009     27.005      0.000       0.228       0.264\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "df.past_arrests.replace(0, 1, inplace=True)\n",
    "\n",
    "formula = 'stops ~ pop + black + hispanic'\n",
    "response, predictors = dmatrices(formula, df, return_type='dataframe')\n",
    "\n",
    "glm_pois = GLM(response, predictors, family=sm.families.Poisson(), exposure=df['past_arrests'])\n",
    "res = glm_pois.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\. According to the output of your model, what fraction fewer or more stops does each ethnicity have with respect to the others, in proportion to arrest rates of the previous year? Note that you can just pick a baseline ethnicity and just compare everything to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: White\n",
      "The Black ethnicity is 1.1887696375463817 more likely to be stopped\n",
      "The Hispanic ethnicity is 1.279264428693029 more likely to be stopped\n"
     ]
    }
   ],
   "source": [
    "# black and hispanic coefs (baseline is white)\n",
    "b = np.exp(res._results.params['x2'])\n",
    "h = np.exp(res._results.params['x3'])\n",
    "\n",
    "# round((b-1) * 100, 2)\n",
    "print('Baseline: White')\n",
    "print('The Black ethnicity is {} more likely to be stopped'.format(b))\n",
    "print('The Hispanic ethnicity is {} more likely to be stopped'.format(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\\. Next, add the 75 precincts, and again solve the Poisson regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  stops   No. Observations:                  900\n",
      "Model:                            GLM   Df Residuals:                      822\n",
      "Model Family:                 Poisson   Df Model:                           77\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -72943.\n",
      "Date:                Thu, 17 Oct 2019   Deviance:                   1.4055e+05\n",
      "Time:                        10:32:58   Pearson chi2:                 2.15e+05\n",
      "No. Iterations:                     7   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1267      0.013    -83.858      0.000      -1.153      -1.100\n",
      "pop         3.796e-06   1.42e-07     26.751      0.000    3.52e-06    4.07e-06\n",
      "precint_1     -0.8198      0.051    -16.193      0.000      -0.919      -0.721\n",
      "precint_2     -0.9640      0.053    -18.088      0.000      -1.068      -0.860\n",
      "precint_3     -0.2856      0.025    -11.350      0.000      -0.335      -0.236\n",
      "precint_4      0.3517      0.027     13.163      0.000       0.299       0.404\n",
      "precint_5     -0.5726      0.025    -22.779      0.000      -0.622      -0.523\n",
      "precint_6      0.3253      0.028     11.619      0.000       0.270       0.380\n",
      "precint_7     -0.6513      0.039    -16.709      0.000      -0.728      -0.575\n",
      "precint_8     -1.2168      0.026    -47.703      0.000      -1.267      -1.167\n",
      "precint_9     -0.3646      0.059     -6.216      0.000      -0.480      -0.250\n",
      "precint_10    -0.4119      0.030    -13.946      0.000      -0.470      -0.354\n",
      "precint_11    -0.3711      0.035    -10.748      0.000      -0.439      -0.303\n",
      "precint_12     0.2773      0.033      8.285      0.000       0.212       0.343\n",
      "precint_13     0.1324      0.021      6.219      0.000       0.091       0.174\n",
      "precint_14    -0.2927      0.029    -10.045      0.000      -0.350      -0.236\n",
      "precint_15     0.1631      0.021      7.899      0.000       0.123       0.204\n",
      "precint_16    -0.0714      0.032     -2.223      0.026      -0.134      -0.008\n",
      "precint_17    -0.9770      0.032    -30.192      0.000      -1.040      -0.914\n",
      "precint_18    -0.7907      0.021    -38.319      0.000      -0.831      -0.750\n",
      "precint_19    -0.7125      0.028    -25.640      0.000      -0.767      -0.658\n",
      "precint_20    -0.9744      0.025    -38.673      0.000      -1.024      -0.925\n",
      "precint_21    -0.5954      0.025    -23.781      0.000      -0.644      -0.546\n",
      "precint_22     0.2529      0.016     15.805      0.000       0.222       0.284\n",
      "precint_23    -0.2824      0.021    -13.517      0.000      -0.323      -0.241\n",
      "precint_24     0.3951      0.020     20.153      0.000       0.357       0.434\n",
      "precint_25    -0.1614      0.017     -9.298      0.000      -0.195      -0.127\n",
      "precint_26    -1.1731      0.026    -45.883      0.000      -1.223      -1.123\n",
      "precint_27     1.0064      0.022     44.937      0.000       0.962       1.050\n",
      "precint_28    -1.7968      0.033    -54.088      0.000      -1.862      -1.732\n",
      "precint_29     0.0545      0.019      2.812      0.005       0.017       0.093\n",
      "precint_30    -0.3932      0.022    -18.216      0.000      -0.436      -0.351\n",
      "precint_31     0.7561      0.024     32.095      0.000       0.710       0.802\n",
      "precint_32     0.5001      0.031     16.207      0.000       0.440       0.561\n",
      "precint_33     0.1051      0.019      5.676      0.000       0.069       0.141\n",
      "precint_34     0.6227      0.019     32.782      0.000       0.585       0.660\n",
      "precint_35    -0.1304      0.037     -3.509      0.000      -0.203      -0.058\n",
      "precint_36     0.5926      0.029     20.217      0.000       0.535       0.650\n",
      "precint_37     0.5050      0.031     16.034      0.000       0.443       0.567\n",
      "precint_38     0.8273      0.024     35.171      0.000       0.781       0.873\n",
      "precint_39    -0.8550      0.026    -33.348      0.000      -0.905      -0.805\n",
      "precint_40     0.5917      0.034     17.371      0.000       0.525       0.658\n",
      "precint_41     1.0478      0.023     46.118      0.000       1.003       1.092\n",
      "precint_42     0.0281      0.020      1.414      0.157      -0.011       0.067\n",
      "precint_43    -0.5798      0.026    -22.643      0.000      -0.630      -0.530\n",
      "precint_44    -0.0984      0.025     -3.996      0.000      -0.147      -0.050\n",
      "precint_45    -0.2312      0.019    -12.018      0.000      -0.269      -0.194\n",
      "precint_46    -0.4282      0.018    -23.821      0.000      -0.463      -0.393\n",
      "precint_47     0.2732      0.032      8.658      0.000       0.211       0.335\n",
      "precint_48    -0.6983      0.026    -26.838      0.000      -0.749      -0.647\n",
      "precint_49     0.2532      0.031      8.170      0.000       0.192       0.314\n",
      "precint_50    -0.1345      0.019     -7.266      0.000      -0.171      -0.098\n",
      "precint_51    -0.6865      0.029    -23.748      0.000      -0.743      -0.630\n",
      "precint_52    -0.4976      0.022    -22.774      0.000      -0.540      -0.455\n",
      "precint_53    -0.2494      0.029     -8.674      0.000      -0.306      -0.193\n",
      "precint_54    -0.4534      0.032    -14.374      0.000      -0.515      -0.392\n",
      "precint_55    -0.4708      0.030    -15.947      0.000      -0.529      -0.413\n",
      "precint_56     0.0596      0.042      1.431      0.153      -0.022       0.141\n",
      "precint_57     0.6918      0.034     20.271      0.000       0.625       0.759\n",
      "precint_58     0.6517      0.019     33.436      0.000       0.614       0.690\n",
      "precint_59     0.1911      0.029      6.500      0.000       0.133       0.249\n",
      "precint_60    -0.1765      0.019     -9.387      0.000      -0.213      -0.140\n",
      "precint_61     0.3249      0.025     13.098      0.000       0.276       0.374\n",
      "precint_62     0.0833      0.026      3.248      0.001       0.033       0.134\n",
      "precint_63     0.4089      0.028     14.511      0.000       0.354       0.464\n",
      "precint_64     0.8119      0.027     29.955      0.000       0.759       0.865\n",
      "precint_65     1.0122      0.021     47.987      0.000       0.971       1.054\n",
      "precint_66     1.1257      0.019     60.558      0.000       1.089       1.162\n",
      "precint_67     0.2549      0.020     12.455      0.000       0.215       0.295\n",
      "precint_68     1.2826      0.030     42.720      0.000       1.224       1.341\n",
      "precint_69     0.8352      0.028     29.768      0.000       0.780       0.890\n",
      "precint_70    -0.1462      0.022     -6.593      0.000      -0.190      -0.103\n",
      "precint_71     0.5215      0.019     28.072      0.000       0.485       0.558\n",
      "precint_72     0.4754      0.017     27.772      0.000       0.442       0.509\n",
      "precint_73     0.0594      0.017      3.557      0.000       0.027       0.092\n",
      "precint_74     0.0528      0.028      1.862      0.063      -0.003       0.108\n",
      "precint_75     0.6840      0.055     12.341      0.000       0.575       0.793\n",
      "black          0.5776      0.012     49.881      0.000       0.555       0.600\n",
      "hispanic       0.5650      0.011     50.422      0.000       0.543       0.587\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "unique_precints = df.precint.unique()\n",
    "precints = pd.get_dummies(df, columns=['precint'])\n",
    "precints.head()\n",
    "\n",
    "precint_list = []\n",
    "for i in range(1, 76):\n",
    "    precint_list.append('precint_{}'.format(i))\n",
    "    \n",
    "precint_str = ' + '.join(precint_list)\n",
    "\n",
    "formula = 'stops ~ pop + {} + black + hispanic'.format(precint_str)\n",
    "response, predictors = dmatrices(formula, precints, return_type='dataframe')\n",
    "\n",
    "glm_pois = GLM(response, predictors, family=sm.families.Poisson(), exposure=precints['past_arrests'])\n",
    "res = glm_pois.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6\\. Now, controlling for precincts, according to your model, what fraction fewer or more stops does each ethnicity have with respect to the others, in proportion to arrest rates of the previous year? (Again, just report with respect to a chosen ethnicity as a baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: White\n",
      "The Black ethnicity is 1.7818306375027062 more likely to be stopped\n",
      "The Hispanic ethnicity is 1.759506746246353 more likely to be stopped\n"
     ]
    }
   ],
   "source": [
    "# black and hispanic coefs (baseline is white)\n",
    "b = np.exp(res._results.params['x77'])\n",
    "h = np.exp(res._results.params['x78'])\n",
    "\n",
    "print('Baseline: White')\n",
    "print('The Black ethnicity is {} more likely to be stopped'.format(b))\n",
    "print('The Hispanic ethnicity is {} more likely to be stopped'.format(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "In this problem you will play with the idea of compound models. I have created a data set\n",
    "(entirely fake!) of 2012 salaries in the NBA, of 10,000 basketball players that were in high-school\n",
    "in 2011: nba cc fake data.csv. Note that the vast majority of the salaries are equal to 0 because\n",
    "the vast majority of these high-school players did not make it to the NBA and hence their NBA\n",
    "salary equals zero.\n",
    "There are three features you will use: height (in inches), average points scored during the last\n",
    "year in high school competition, and a scoring from 1-10 of the competitiveness of the league these\n",
    "players played in, with 10 being the most competitive.\n",
    "The goal is to build a model to predict the NBA salary of a high school baller.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp</th>\n",
       "      <th>Height</th>\n",
       "      <th>Points</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Comp  Height  Points  Salary\n",
       "0   9.0    76.0    27.0     0.0\n",
       "1   7.0    78.0    39.0     0.0\n",
       "2   9.0    76.0    39.0     0.0\n",
       "3   9.0    74.0    39.0     0.0\n",
       "4   9.0    74.0    26.0     0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 5.88% of the players make it to the NBA.\n",
    "nba_data = pd.read_csv(\"nba_cc_fake_data.csv\", index_col=0)\n",
    "nba_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 587)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nba_data), len(nba_data[nba_data['Salary']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176939.0, 1212013.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0]['Salary'].min(), nba_data[nba_data['Salary']>0]['Salary'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\. Explain why linear regression is not appropriate, given the nature of the data.\n",
    "From the result shown above, we can find that there are 10000 samples in total, but only 587 of them has a value rather than 0 in the predicted column (Salary). Also, the nature of salary data should be a range of different numbers, there will be a great gap between the start (0) and start of non-zero (176939). Therefore, the biased data doesn't fit well in Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\. Try least squares regression, anyway. How well do you do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training set and testing set\n",
    "X = nba_data.values[:, :3]\n",
    "Y = nba_data.values[:, 3]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 socre for Ordinary Least Squares is 0.18\n"
     ]
    }
   ],
   "source": [
    "# # Test for linear regression - ordinary least square method\n",
    "LinearReg = LinearRegression()\n",
    "LinearReg.fit(X_train, y_train)\n",
    "print(\"R2 socre for Ordinary Least Squares is %.2f\" % r2_score(y_test, LinearReg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the $R^2$ score above, the performance of Least Squares Regression is almost the same as randomly guess which is bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\. You will next build a composite model.\n",
    "You will first predict the probability that a player\n",
    "actually makes it to the NBA at all, and then you will build a model to predict the salary of\n",
    "a player, conditioned on the fact of making it to the NBA.<br>\n",
    "– Build a model that predicts the probability of making it to the NBA.<br>\n",
    "– Do a train-test split of 8000/2000 points, train your best model on the training set, and\n",
    "compute the AUC on the test set.<br>\n",
    "– Now, build a model to predict the salary. Note that you may wish to consider a nonlinear transformation of your data. What is your R2\n",
    "score on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build a model that predicts the probability of making it to the NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use the Logistic Regression to predict probability that a player actually makes it to the NBA.\n",
    "# Before fitting into the model, transfer the predicted column into 0 and 1.\n",
    "Y_pro = np.copy(Y)\n",
    "Y_pro[np.where(Y>0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of the hyperparamenter stratify is None, which means data is split in a stratified fashion.\n",
    "X_train_pro, X_test_pro, y_train_pro, y_test_pro = train_test_split(X, Y_pro, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aucModel(clf, model_name, X_train=X_train_pro, y_train=y_train_pro, X_test=X_test_pro, y_test=y_test_pro):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"AUC score of %s\"%model_name + \" on the training set is %.4f\" % roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])) \n",
    "    print(\"AUC score of %s\"%model_name + \" on the testing set is %.4f\" % roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Do a train-test split of 8000/2000 points, train your best model on the training set, and compute the AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda2\\envs\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Logistic Regression on the training set is 0.9005\n",
      "AUC score of Logistic Regression on the testing set is 0.9133\n"
     ]
    }
   ],
   "source": [
    "# First, let's use a Logistic Regression model to test the performance.\n",
    "pro_LR = LogisticRegression()\n",
    "aucModel(pro_LR, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the AUC score of Logistic Regression printed above, the performance of this model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Decision Tree on the training set is 0.9494\n",
      "AUC score of Decision Tree on the testing set is 0.9249\n"
     ]
    }
   ],
   "source": [
    "# We try Decision Tree here.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecTree = DecisionTreeClassifier(max_depth=6)\n",
    "aucModel(DecTree, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Gradient Boosting Classifier on the training set is 0.9501\n",
      "AUC score of Gradient Boosting Classifier on the testing set is 0.9383\n"
     ]
    }
   ],
   "source": [
    "# This time, we try gradient boosting of trees.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GradBoost = GradientBoostingClassifier(n_estimators=30, max_depth=4)\n",
    "aucModel(GradBoost, \"Gradient Boosting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Random Forest on the training set is 0.9390\n",
      "AUC score of Random Forest on the testing set is 0.9380\n"
     ]
    }
   ],
   "source": [
    "# What about Random Forest which reduces the variance?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandForest = RandomForestClassifier(n_estimators=8, max_depth=5)\n",
    "aucModel(RandForest, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment results above, we find that among these models, Gradient Boosting Classifier and Random Forest perform best. Here, we choose Gradient Boosting Classifier as our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Now, build a model to predict the salary. Note that you may wish to consider a nonlinear transformation of your data. What is your R2 score on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, build a model to predict the salary.\n",
    "# As the range of salary is very wide, first filter the data by salary > 0.\n",
    "X_salary = np.copy(X[np.where(Y>0)])\n",
    "Y_salary = np.copy(Y[np.where(Y>0)])\n",
    "X_train_sal, X_test_sal, y_train_sal, y_test_sal = train_test_split(X_salary, Y_salary, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get some insights from origin data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp</th>\n",
       "      <th>Height</th>\n",
       "      <th>Points</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Comp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>-0.254520</td>\n",
       "      <td>0.664805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Height</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.210574</td>\n",
       "      <td>0.259522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Points</td>\n",
       "      <td>-0.254520</td>\n",
       "      <td>-0.210574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Salary</td>\n",
       "      <td>0.664805</td>\n",
       "      <td>0.259522</td>\n",
       "      <td>-0.057897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Comp    Height    Points    Salary\n",
       "Comp    1.000000 -0.060623 -0.254520  0.664805\n",
       "Height -0.060623  1.000000 -0.210574  0.259522\n",
       "Points -0.254520 -0.210574  1.000000 -0.057897\n",
       "Salary  0.664805  0.259522 -0.057897  1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation matrix, we can find that there is no co-linearty in features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comp      0.729033\n",
       "Height    0.246162\n",
       "Points   -0.065791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0][['Comp', 'Height', 'Points']].corrwith(np.log(nba_data[nba_data['Salary']>0]['Salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2LR(clf, data_name, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"R2 score for %s\"%data_name + \" is:\")\n",
    "    print(\"Training score: %.4f\" % r2_score(y_train, clf.predict(X_train)))\n",
    "    print(\"Testing score:  %.4f\" % r2_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for filtered data is:\n",
      "Training score: 0.5601\n",
      "Testing score:  0.5932\n"
     ]
    }
   ],
   "source": [
    "preLR = LinearRegression()\n",
    "r2LR(preLR, \"filtered data\", X_train_sal, X_test_sal, y_train_sal, y_test_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, try standardizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "x_sc.fit(X_train_sal)\n",
    "X_train_sal_std = x_sc.transform(X_train_sal)\n",
    "X_test_sal_std = x_sc.transform(X_test_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for standardized data is:\n",
      "Training score: 0.5601\n",
      "Testing score:  0.5932\n"
     ]
    }
   ],
   "source": [
    "# First, try standardizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "x_sc.fit(X_train_sal)\n",
    "X_train_sal_std = x_sc.transform(X_train_sal)\n",
    "X_test_sal_std = x_sc.transform(X_test_sal)\n",
    "\n",
    "y_sc = StandardScaler()\n",
    "y_sc.fit(y_train_sal.reshape(-1, 1))\n",
    "y_train_sal_std = y_sc.transform(y_train_sal.reshape(-1, 1))\n",
    "y_test_sal_std = y_sc.transform(y_test_sal.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "preLR_std = LinearRegression()\n",
    "r2LR(preLR_std, \"standardized data\", X_train_sal_std, X_test_sal_std, y_train_sal_std, y_test_sal_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for logged salary is:\n",
      "Training score: 0.6441\n",
      "Testing score:  0.6871\n"
     ]
    }
   ],
   "source": [
    "# It seems that standardization does not help improve the performance of predictions.\n",
    "# As the salary is in a relative high range, try log.\n",
    "y_train_log = np.log(y_train_sal)\n",
    "y_test_log = np.log(y_test_sal)\n",
    "preLR_log = LinearRegression()\n",
    "r2LR(preLR_log, \"logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Decision Tree Regressor (max depth = 3) with logged salary is:\n",
      "Training score: 0.6009\n",
      "Testing score:  0.6125\n",
      "R2 score for Decision Tree Regressor (max depth = 4) with logged salary is:\n",
      "Training score: 0.6516\n",
      "Testing score:  0.6007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "preDTR = DecisionTreeRegressor(max_depth=3)\n",
    "r2LR(preDTR, \"Decision Tree Regressor (max depth = 3) with logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)\n",
    "preDTR = DecisionTreeRegressor(max_depth=4)\n",
    "r2LR(preDTR, \"Decision Tree Regressor (max depth = 4) with logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Gradient Boosting Regressor (max depth = 3) is:\n",
      "Training score: 0.6883\n",
      "Testing score:  0.6514\n"
     ]
    }
   ],
   "source": [
    "# This time, we try gradient boosting of trees.\n",
    "# This is the best result of manually tuning.\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "preGradBoost = GradientBoostingRegressor(n_estimators=30, max_depth=3)\n",
    "r2LR(preGradBoost, \"Gradient Boosting Regressor (max depth = 3)\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Random Forest Regressor (max depth = 5) is:\n",
      "Training score: 0.7039\n",
      "Testing score:  0.6843\n"
     ]
    }
   ],
   "source": [
    "# What about Random Forest which reduces the variance?\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "preRandForest = RandomForestRegressor(n_estimators=8, max_depth=5)\n",
    "r2LR(preRandForest, \"Random Forest Regressor (max depth = 5)\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model in predicting salary is the Random Forest Regressor. <br>\n",
    "In summary, we choose the best model to predict the probability of a player that makes it to the NBA and another regression model to predict the salary if the player is making it the NBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\.  Test for given sample\n",
    "Compute the expected NBA salary of a high school basketball player who is 6’ 6” tall, is\n",
    "averaging 46 points per game, and is playing in the second most competitive league (comp =\n",
    "9), according to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predPlayer(player, prob_clf, pred_clf, threshold = 0.5):\n",
    "    # Predict the probability of this player that makes it to the NBA\n",
    "    prob = prob_clf.predict_proba(player)[0][1]\n",
    "    print((\"The data for the player is:\\nCompetitive Leagure: {} \\nHeight: {}\\nPoints: {}\").format(player[0][0], player[0][1], player[0][2]))\n",
    "    print(\"The probability of this player making it to the NBA is %f\"%prob)\n",
    "    if (prob > threshold):\n",
    "        pred_sal = pred_clf.predict(player)[0]**10\n",
    "        print(\"The predicted salary for this player is %.2f\"%pred_sal)\n",
    "    else:\n",
    "        print(\"As the player does not prefer to making it to the NBA, the salary is 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = np.array([[9, 78, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the player is:\n",
      "Competitive Leagure: 9 \n",
      "Height: 78\n",
      "Points: 46\n",
      "The probability of this player making it to the NBA is 0.068136\n",
      "As the player does not prefer to making it to the NBA, the salary is 0.\n"
     ]
    }
   ],
   "source": [
    "predPlayer(player, GradBoost, preRandForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
