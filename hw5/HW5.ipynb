{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "In this problem you will play with the idea of compound models. I have created a data set\n",
    "(entirely fake!) of 2012 salaries in the NBA, of 10,000 basketball players that were in high-school\n",
    "in 2011: nba cc fake data.csv. Note that the vast majority of the salaries are equal to 0 because\n",
    "the vast majority of these high-school players did not make it to the NBA and hence their NBA\n",
    "salary equals zero.\n",
    "There are three features you will use: height (in inches), average points scored during the last\n",
    "year in high school competition, and a scoring from 1-10 of the competitiveness of the league these\n",
    "players played in, with 10 being the most competitive.\n",
    "The goal is to build a model to predict the NBA salary of a high school baller.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp</th>\n",
       "      <th>Height</th>\n",
       "      <th>Points</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Comp  Height  Points  Salary\n",
       "0   9.0    76.0    27.0     0.0\n",
       "1   7.0    78.0    39.0     0.0\n",
       "2   9.0    76.0    39.0     0.0\n",
       "3   9.0    74.0    39.0     0.0\n",
       "4   9.0    74.0    26.0     0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 5.88% of the players make it to the NBA.\n",
    "nba_data = pd.read_csv(\"nba_cc_fake_data.csv\", index_col=0)\n",
    "nba_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 587)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nba_data), len(nba_data[nba_data['Salary']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176939.0, 1212013.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0]['Salary'].min(), nba_data[nba_data['Salary']>0]['Salary'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\. Explain why linear regression is not appropriate, given the nature of the data.\n",
    "From the result shown above, we can find that there are 10000 samples in total, but only 587 of them has a value rather than 0 in the predicted column (Salary). Also, the nature of salary data should be a range of different numbers, there will be a great gap between the start (0) and start of non-zero (176939). Therefore, the biased data doesn't fit well in Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\. Try least squares regression, anyway. How well do you do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training set and testing set\n",
    "X = nba_data.values[:, :3]\n",
    "Y = nba_data.values[:, 3]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 socre for Ordinary Least Squares is 0.18\n"
     ]
    }
   ],
   "source": [
    "# # Test for linear regression - ordinary least square method\n",
    "LinearReg = LinearRegression()\n",
    "LinearReg.fit(X_train, y_train)\n",
    "print(\"R2 socre for Ordinary Least Squares is %.2f\" % r2_score(y_test, LinearReg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the $R^2$ score above, the performance of Least Squares Regression is almost the same as randomly guess which is bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\. You will next build a composite model.\n",
    "You will first predict the probability that a player\n",
    "actually makes it to the NBA at all, and then you will build a model to predict the salary of\n",
    "a player, conditioned on the fact of making it to the NBA.<br>\n",
    "– Build a model that predicts the probability of making it to the NBA.<br>\n",
    "– Do a train-test split of 8000/2000 points, train your best model on the training set, and\n",
    "compute the AUC on the test set.<br>\n",
    "– Now, build a model to predict the salary. Note that you may wish to consider a nonlinear transformation of your data. What is your R2\n",
    "score on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build a model that predicts the probability of making it to the NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use the Logistic Regression to predict probability that a player actually makes it to the NBA.\n",
    "# Before fitting into the model, transfer the predicted column into 0 and 1.\n",
    "Y_pro = np.copy(Y)\n",
    "Y_pro[np.where(Y>0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value of the hyperparamenter stratify is None, which means data is split in a stratified fashion.\n",
    "X_train_pro, X_test_pro, y_train_pro, y_test_pro = train_test_split(X, Y_pro, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aucModel(clf, model_name, X_train=X_train_pro, y_train=y_train_pro, X_test=X_test_pro, y_test=y_test_pro):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"AUC score of %s\"%model_name + \" on the training set is %.4f\" % roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])) \n",
    "    print(\"AUC score of %s\"%model_name + \" on the testing set is %.4f\" % roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Do a train-test split of 8000/2000 points, train your best model on the training set, and compute the AUC on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda2\\envs\\Python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Logistic Regression on the training set is 0.9005\n",
      "AUC score of Logistic Regression on the testing set is 0.9133\n"
     ]
    }
   ],
   "source": [
    "# First, let's use a Logistic Regression model to test the performance.\n",
    "pro_LR = LogisticRegression()\n",
    "aucModel(pro_LR, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the AUC score of Logistic Regression printed above, the performance of this model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Decision Tree on the training set is 0.9494\n",
      "AUC score of Decision Tree on the testing set is 0.9249\n"
     ]
    }
   ],
   "source": [
    "# We try Decision Tree here.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecTree = DecisionTreeClassifier(max_depth=6)\n",
    "aucModel(DecTree, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Gradient Boosting Classifier on the training set is 0.9501\n",
      "AUC score of Gradient Boosting Classifier on the testing set is 0.9383\n"
     ]
    }
   ],
   "source": [
    "# This time, we try gradient boosting of trees.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GradBoost = GradientBoostingClassifier(n_estimators=30, max_depth=4)\n",
    "aucModel(GradBoost, \"Gradient Boosting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score of Random Forest on the training set is 0.9390\n",
      "AUC score of Random Forest on the testing set is 0.9380\n"
     ]
    }
   ],
   "source": [
    "# What about Random Forest which reduces the variance?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandForest = RandomForestClassifier(n_estimators=8, max_depth=5)\n",
    "aucModel(RandForest, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment results above, we find that among these models, Gradient Boosting Classifier and Random Forest perform best. Here, we choose Gradient Boosting Classifier as our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Now, build a model to predict the salary. Note that you may wish to consider a nonlinear transformation of your data. What is your R2 score on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, build a model to predict the salary.\n",
    "# As the range of salary is very wide, first filter the data by salary > 0.\n",
    "X_salary = np.copy(X[np.where(Y>0)])\n",
    "Y_salary = np.copy(Y[np.where(Y>0)])\n",
    "X_train_sal, X_test_sal, y_train_sal, y_test_sal = train_test_split(X_salary, Y_salary, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get some insights from origin data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp</th>\n",
       "      <th>Height</th>\n",
       "      <th>Points</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Comp</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>-0.254520</td>\n",
       "      <td>0.664805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Height</td>\n",
       "      <td>-0.060623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.210574</td>\n",
       "      <td>0.259522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Points</td>\n",
       "      <td>-0.254520</td>\n",
       "      <td>-0.210574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Salary</td>\n",
       "      <td>0.664805</td>\n",
       "      <td>0.259522</td>\n",
       "      <td>-0.057897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Comp    Height    Points    Salary\n",
       "Comp    1.000000 -0.060623 -0.254520  0.664805\n",
       "Height -0.060623  1.000000 -0.210574  0.259522\n",
       "Points -0.254520 -0.210574  1.000000 -0.057897\n",
       "Salary  0.664805  0.259522 -0.057897  1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation matrix, we can find that there is no co-linearty in features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comp      0.729033\n",
       "Height    0.246162\n",
       "Points   -0.065791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_data[nba_data['Salary']>0][['Comp', 'Height', 'Points']].corrwith(np.log(nba_data[nba_data['Salary']>0]['Salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2LR(clf, data_name, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"R2 score for %s\"%data_name + \" is:\")\n",
    "    print(\"Training score: %.4f\" % r2_score(y_train, clf.predict(X_train)))\n",
    "    print(\"Testing score:  %.4f\" % r2_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for filtered data is:\n",
      "Training score: 0.5601\n",
      "Testing score:  0.5932\n"
     ]
    }
   ],
   "source": [
    "preLR = LinearRegression()\n",
    "r2LR(preLR, \"filtered data\", X_train_sal, X_test_sal, y_train_sal, y_test_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, try standardizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "x_sc.fit(X_train_sal)\n",
    "X_train_sal_std = x_sc.transform(X_train_sal)\n",
    "X_test_sal_std = x_sc.transform(X_test_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for standardized data is:\n",
      "Training score: 0.5601\n",
      "Testing score:  0.5932\n"
     ]
    }
   ],
   "source": [
    "# First, try standardizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "x_sc.fit(X_train_sal)\n",
    "X_train_sal_std = x_sc.transform(X_train_sal)\n",
    "X_test_sal_std = x_sc.transform(X_test_sal)\n",
    "\n",
    "y_sc = StandardScaler()\n",
    "y_sc.fit(y_train_sal.reshape(-1, 1))\n",
    "y_train_sal_std = y_sc.transform(y_train_sal.reshape(-1, 1))\n",
    "y_test_sal_std = y_sc.transform(y_test_sal.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "preLR_std = LinearRegression()\n",
    "r2LR(preLR_std, \"standardized data\", X_train_sal_std, X_test_sal_std, y_train_sal_std, y_test_sal_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for logged salary is:\n",
      "Training score: 0.6441\n",
      "Testing score:  0.6871\n"
     ]
    }
   ],
   "source": [
    "# It seems that standardization does not help improve the performance of predictions.\n",
    "# As the salary is in a relative high range, try log.\n",
    "y_train_log = np.log(y_train_sal)\n",
    "y_test_log = np.log(y_test_sal)\n",
    "preLR_log = LinearRegression()\n",
    "r2LR(preLR_log, \"logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Decision Tree Regressor (max depth = 3) with logged salary is:\n",
      "Training score: 0.6009\n",
      "Testing score:  0.6125\n",
      "R2 score for Decision Tree Regressor (max depth = 4) with logged salary is:\n",
      "Training score: 0.6516\n",
      "Testing score:  0.6007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "preDTR = DecisionTreeRegressor(max_depth=3)\n",
    "r2LR(preDTR, \"Decision Tree Regressor (max depth = 3) with logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)\n",
    "preDTR = DecisionTreeRegressor(max_depth=4)\n",
    "r2LR(preDTR, \"Decision Tree Regressor (max depth = 4) with logged salary\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Gradient Boosting Regressor (max depth = 3) is:\n",
      "Training score: 0.6883\n",
      "Testing score:  0.6514\n"
     ]
    }
   ],
   "source": [
    "# This time, we try gradient boosting of trees.\n",
    "# This is the best result of manually tuning.\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "preGradBoost = GradientBoostingRegressor(n_estimators=30, max_depth=3)\n",
    "r2LR(preGradBoost, \"Gradient Boosting Regressor (max depth = 3)\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Random Forest Regressor (max depth = 5) is:\n",
      "Training score: 0.7039\n",
      "Testing score:  0.6843\n"
     ]
    }
   ],
   "source": [
    "# What about Random Forest which reduces the variance?\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "preRandForest = RandomForestRegressor(n_estimators=8, max_depth=5)\n",
    "r2LR(preRandForest, \"Random Forest Regressor (max depth = 5)\", X_train_sal, X_test_sal, y_train_log, y_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model in predicting salary is the Random Forest Regressor. <br>\n",
    "In summary, we choose the best model to predict the probability of a player that makes it to the NBA and another regression model to predict the salary if the player is making it the NBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\.  Test for given sample\n",
    "Compute the expected NBA salary of a high school basketball player who is 6’ 6” tall, is\n",
    "averaging 46 points per game, and is playing in the second most competitive league (comp =\n",
    "9), according to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predPlayer(player, prob_clf, pred_clf, threshold = 0.5):\n",
    "    # Predict the probability of this player that makes it to the NBA\n",
    "    prob = prob_clf.predict_proba(player)[0][1]\n",
    "    print((\"The data for the player is:\\nCompetitive Leagure: {} \\nHeight: {}\\nPoints: {}\").format(player[0][0], player[0][1], player[0][2]))\n",
    "    print(\"The probability of this player making it to the NBA is %f\"%prob)\n",
    "    if (prob > threshold):\n",
    "        pred_sal = pred_clf.predict(player)[0]**10\n",
    "        print(\"The predicted salary for this player is %.2f\"%pred_sal)\n",
    "    else:\n",
    "        print(\"As the player does not prefer to making it to the NBA, the salary is 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = np.array([[9, 78, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the player is:\n",
      "Competitive Leagure: 9 \n",
      "Height: 78\n",
      "Points: 46\n",
      "The probability of this player making it to the NBA is 0.068136\n",
      "As the player does not prefer to making it to the NBA, the salary is 0.\n"
     ]
    }
   ],
   "source": [
    "predPlayer(player, GradBoost, preRandForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
